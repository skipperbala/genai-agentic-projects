{
  "title": "A Novel In-Context Learning Framework for Soft-Input Soft-Output Channel Equalization in Coded Multiple-Input Multiple-Output Systems",
  "abstract": "This paper introduces a novel in-context learning (ICL) framework, inspired by large language models (LLMs), for soft-input soft-output channel equalization in coded multiple-input multiple-output (MIMO) systems. The proposed approach learns to infer posterior symbol distributions directly from a prompt of pilot signals and decoder feedback. A key innovation is the use of prompt augmentation to incorporate extrinsic information from the decoder output as additional context, enabling the ICL model to refine its symbol estimates iteratively across turbo decoding iterations. Two model variants, based on Transformer and state-space architectures, are developed and evaluated. Extensive simulations demonstrate that, when traditional linear assumptions break down, e.g., in the presence of low-resolution quantization, ICL equalizers consistently outperform conventional model-based baselines, even when the latter are provided with perfect channel state information. Results also highlight the advantage of Transformer-based models under limited training diversity, as well as the efficiency of state-space models in resource-constrained scenarios.",
  "problem": "The challenge of soft-input soft-output channel equalization in coded multiple-input multiple-output (MIMO) systems, particularly when traditional linear assumptions break down, such as in the presence of low-resolution quantization.",
  "methodology": "The proposed in-context learning (ICL) framework learns to infer posterior symbol distributions directly from a prompt of pilot signals and decoder feedback. The use of prompt augmentation incorporates extrinsic information from the decoder output as additional context, enabling the ICL model to refine its symbol estimates iteratively across turbo decoding iterations. Two model variants, based on Transformer and state-space architectures, are developed and evaluated through extensive simulations.",
  "limitations": "The paper does not explicitly mention any limitations of the proposed framework.",
  "future_work": "The paper does not explicitly mention any suggested future work. However, further improvements and optimizations of the proposed ICL framework, as well as its application in other related fields, could be potential areas for future investigation."
}